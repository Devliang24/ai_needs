# AutoGen å¿«é€Ÿå…¥é—¨

## ä»€ä¹ˆæ˜¯ AutoGenï¼Ÿ

**AutoGen** æ˜¯ç”±å¾®è½¯å¼€å‘çš„å¼€æºæ¡†æ¶ï¼Œç”¨äºæ„å»ºåŸºäºå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„å¤šæ™ºèƒ½ä½“ç³»ç»Ÿã€‚å®ƒè®©å¤šä¸ª AI æ™ºèƒ½ä½“èƒ½å¤Ÿç›¸äº’å¯¹è¯ã€åä½œå®Œæˆå¤æ‚ä»»åŠ¡ã€‚

### æ ¸å¿ƒæ¦‚å¿µ

| æ¦‚å¿µ | è¯´æ˜ | ç±»æ¯” |
|------|------|------|
| **Agentï¼ˆæ™ºèƒ½ä½“ï¼‰** | å…·æœ‰ç‰¹å®šè§’è‰²å’Œèƒ½åŠ›çš„ AI å®ä½“ | å›¢é˜Ÿä¸­çš„ä¸åŒå²—ä½ï¼ˆäº§å“ç»ç†ã€å¼€å‘ã€æµ‹è¯•ï¼‰ |
| **Conversationï¼ˆå¯¹è¯ï¼‰** | æ™ºèƒ½ä½“ä¹‹é—´çš„æ¶ˆæ¯äº¤äº’ | å›¢é˜Ÿæˆå‘˜ä¹‹é—´çš„å·¥ä½œæ²Ÿé€š |
| **LLM Configï¼ˆæ¨¡å‹é…ç½®ï¼‰** | è¿æ¥å’Œé…ç½®åº•å±‚å¤§è¯­è¨€æ¨¡å‹ | å›¢é˜Ÿæˆå‘˜çš„æŠ€èƒ½å’Œå·¥å…· |

### ä¸ºä»€ä¹ˆé€‰æ‹© AutoGenï¼Ÿ

- âœ… **ç®€åŒ–å¤šæ™ºèƒ½ä½“å¼€å‘**ï¼šæ— éœ€è‡ªå·±ç®¡ç†å¯¹è¯çŠ¶æ€å’Œæ¶ˆæ¯ä¼ é€’
- âœ… **çµæ´»çš„æ¨¡å‹æ”¯æŒ**ï¼šå…¼å®¹ OpenAIã€Azureã€é€šä¹‰åƒé—®ç­‰
- âœ… **ç”Ÿäº§çº§ç‰¹æ€§**ï¼šé”™è¯¯å¤„ç†ã€é‡è¯•ã€è¶…æ—¶æ§åˆ¶ç­‰å¼€ç®±å³ç”¨

## ç¯å¢ƒé…ç½®

### 1. å®‰è£… AutoGen

```bash
pip install pyautogen==0.2.0
```

### 2. å®‰è£… LLM SDKï¼ˆä»¥é€šä¹‰åƒé—®ä¸ºä¾‹ï¼‰

```bash
pip install openai==1.10.0
pip install dashscope>=1.24.6
```

### 3. é…ç½® API å¯†é’¥

åˆ›å»º `.env` æ–‡ä»¶ï¼š

```bash
QWEN_API_KEY=sk-your-api-key-here
QWEN_BASE_URL=https://dashscope.aliyuncs.com/compatible-mode/v1
QWEN_MODEL=qwen-plus
```

## ç¬¬ä¸€ä¸ª AutoGen ç¨‹åº

### ç¤ºä¾‹ 1ï¼šå•ä¸ªæ™ºèƒ½ä½“

```python
from autogen import AssistantAgent

# é…ç½® LLM
llm_config = {
    "config_list": [{
        "model": "qwen-plus",
        "api_key": "sk-your-api-key",
        "base_url": "https://dashscope.aliyuncs.com/compatible-mode/v1"
    }],
    "timeout": 120,
}

# åˆ›å»ºæ™ºèƒ½ä½“
assistant = AssistantAgent(
    name="assistant",
    system_message="ä½ æ˜¯ä¸€ä½å‹å¥½çš„AIåŠ©æ‰‹ã€‚",
    llm_config=llm_config,
    human_input_mode="NEVER",
    max_consecutive_auto_reply=1,
)

# ç”Ÿæˆå›å¤
response = assistant.generate_reply(
    messages=[{"role": "user", "content": "ä½ å¥½ï¼Œä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±"}]
)

print(response)
```

**è¾“å‡ºç¤ºä¾‹**ï¼š
```
ä½ å¥½ï¼æˆ‘æ˜¯ä¸€ä½AIåŠ©æ‰‹ï¼ŒåŸºäºå¤§è¯­è¨€æ¨¡å‹æ„å»º...
```

### ç¤ºä¾‹ 2ï¼šé¡¹ç›®ä¸­çš„æ™ºèƒ½ä½“åˆ›å»ºï¼ˆçœŸå®ä»£ç ï¼‰

ä» `backend/app/llm/autogen_runner.py` ä¸­æå–ï¼š

```python
from autogen import AssistantAgent

def create_agent(system_message: str, agent_type: str = "default") -> AssistantAgent:
    """åˆ›å»ºæ™ºèƒ½ä½“ï¼Œæ ¹æ®ç±»å‹ä½¿ç”¨ä¸åŒçš„æ¨¡å‹é…ç½®."""
    
    # æ ¹æ®æ™ºèƒ½ä½“ç±»å‹è·å–é…ç½®
    if agent_type == "analysis":
        config = {
            "model": "qwen3-vl-flash",  # éœ€æ±‚åˆ†æç”¨è§†è§‰æ¨¡å‹
            "api_key": "sk-your-key",
            "base_url": "https://dashscope.aliyuncs.com/compatible-mode/v1"
        }
    elif agent_type == "test":
        config = {
            "model": "qwen3-next-80b-a3b-instruct",  # æµ‹è¯•ç”Ÿæˆç”¨å¼ºåŠ›æ¨¡å‹
            "api_key": "sk-your-key",
            "base_url": "https://dashscope.aliyuncs.com/compatible-mode/v1"
        }
    else:
        config = {
            "model": "qwen-plus",  # é»˜è®¤æ¨¡å‹
            "api_key": "sk-your-key",
            "base_url": "https://dashscope.aliyuncs.com/compatible-mode/v1"
        }
    
    return AssistantAgent(
        name=f"{agent_type}_agent",
        system_message=system_message,
        llm_config={
            "config_list": [config],
            "timeout": 120,
        },
        human_input_mode="NEVER",  # ä¸éœ€è¦äººå·¥è¾“å…¥
        max_consecutive_auto_reply=1,  # åªè‡ªåŠ¨å›å¤ä¸€æ¬¡
        code_execution_config=False,  # ç¦ç”¨ä»£ç æ‰§è¡Œ
    )

# åˆ›å»ºéœ€æ±‚åˆ†æå¸ˆ
analyst = create_agent(
    system_message="ä½ æ˜¯ä¸€ä½èµ„æ·±éœ€æ±‚åˆ†æå¸ˆï¼Œæ“…é•¿ä»æ–‡æ¡£ä¸­æå–åŠŸèƒ½æ¨¡å—å’Œä¸šåŠ¡è§„åˆ™ã€‚",
    agent_type="analysis"
)

# ä½¿ç”¨æ™ºèƒ½ä½“
prompt = "è¯·åˆ†æä»¥ä¸‹éœ€æ±‚ï¼šç”¨æˆ·ç™»å½•ç³»ç»Ÿï¼Œæ”¯æŒå¯†ç å’ŒæŒ‡çº¹ä¸¤ç§æ–¹å¼..."
reply = analyst.generate_reply(messages=[{"role": "user", "content": prompt}])
print(reply)
```

## AutoGen vs ç›´æ¥è°ƒç”¨ OpenAI SDK

### ç›´æ¥è°ƒç”¨ OpenAI SDK

```python
from openai import OpenAI

client = OpenAI(api_key="sk-xxx", base_url="https://...")
response = client.chat.completions.create(
    model="qwen-plus",
    messages=[
        {"role": "system", "content": "ä½ æ˜¯ä¸€ä½éœ€æ±‚åˆ†æå¸ˆ"},
        {"role": "user", "content": "åˆ†æè¿™ä¸ªéœ€æ±‚..."}
    ]
)
print(response.choices[0].message.content)
```

### ä½¿ç”¨ AutoGen

```python
from autogen import AssistantAgent

agent = AssistantAgent(
    name="analyst",
    system_message="ä½ æ˜¯ä¸€ä½éœ€æ±‚åˆ†æå¸ˆ",
    llm_config={"config_list": [{"model": "qwen-plus", "api_key": "sk-xxx"}]}
)
reply = agent.generate_reply(messages=[{"role": "user", "content": "åˆ†æè¿™ä¸ªéœ€æ±‚..."}])
print(reply)
```

### å¯¹æ¯”æ€»ç»“

| ç‰¹æ€§ | OpenAI SDK | AutoGen |
|------|-----------|---------|
| **ç®€å•å•æ¬¡è°ƒç”¨** | âœ… æ›´ç®€æ´ | âŒ ç¨æ˜¾å†—é•¿ |
| **å¤šæ™ºèƒ½ä½“åä½œ** | âŒ éœ€è¦æ‰‹åŠ¨å®ç° | âœ… å†…ç½®æ”¯æŒ |
| **å¯¹è¯ä¸Šä¸‹æ–‡ç®¡ç†** | âŒ éœ€è¦æ‰‹åŠ¨ç»´æŠ¤ | âœ… è‡ªåŠ¨ç®¡ç† |
| **é‡è¯•å’Œé”™è¯¯å¤„ç†** | âŒ éœ€è¦æ‰‹åŠ¨å®ç° | âœ… å†…ç½®æ”¯æŒ |
| **é€‚ç”¨åœºæ™¯** | ç®€å•é—®ç­” | å¤æ‚å¤šæ­¥éª¤ä»»åŠ¡ |

## æ ¸å¿ƒ API å¿«é€Ÿå‚è€ƒ

### AssistantAgent å‚æ•°

```python
AssistantAgent(
    name="agent_name",           # æ™ºèƒ½ä½“åç§°ï¼ˆå”¯ä¸€æ ‡è¯†ï¼‰
    system_message="...",        # ç³»ç»Ÿæç¤ºè¯ï¼ˆå®šä¹‰è§’è‰²å’Œèƒ½åŠ›ï¼‰
    llm_config={...},            # LLM é…ç½®ï¼ˆæ¨¡å‹ã€APIå¯†é’¥ç­‰ï¼‰
    human_input_mode="NEVER",    # äººå·¥ä»‹å…¥æ¨¡å¼ï¼šNEVER/TERMINATE/ALWAYS
    max_consecutive_auto_reply=1,# æœ€å¤§è‡ªåŠ¨å›å¤æ¬¡æ•°
    code_execution_config=False, # æ˜¯å¦å…è®¸æ‰§è¡Œä»£ç 
)
```

### generate_reply æ–¹æ³•

```python
response = agent.generate_reply(
    messages=[
        {"role": "user", "content": "ä½ çš„æç¤ºè¯"}
    ]
)
```

**è¿”å›å€¼**ï¼šå­—ç¬¦ä¸²æˆ–å­—å…¸ç±»å‹çš„å›å¤å†…å®¹

## å¸¸è§é—®é¢˜

### 1. å¦‚ä½•åˆ‡æ¢ä¸åŒçš„ LLM æä¾›å•†ï¼Ÿ

åªéœ€ä¿®æ”¹ `llm_config` ä¸­çš„ `base_url` å’Œ `api_key`ï¼š

```python
# OpenAI
config = {"model": "gpt-4", "api_key": "sk-xxx"}

# Azure OpenAI
config = {
    "model": "gpt-4",
    "api_key": "xxx",
    "base_url": "https://your-resource.openai.azure.com/",
    "api_type": "azure",
    "api_version": "2024-02-01"
}

# é€šä¹‰åƒé—®
config = {
    "model": "qwen-plus",
    "api_key": "sk-xxx",
    "base_url": "https://dashscope.aliyuncs.com/compatible-mode/v1"
}
```

### 2. å¦‚ä½•è°ƒè¯•æ™ºèƒ½ä½“çš„è¾“å‡ºï¼Ÿ

```python
import logging
logging.basicConfig(level=logging.INFO)

# AutoGen ä¼šè‡ªåŠ¨æ‰“å°è¯¦ç»†çš„å¯¹è¯æ—¥å¿—
```

### 3. è¶…æ—¶æ€ä¹ˆåŠï¼Ÿ

```python
llm_config = {
    "config_list": [...],
    "timeout": 300,  # å¢åŠ è¶…æ—¶æ—¶é—´åˆ° 5 åˆ†é’Ÿ
}
```

## ä¸‹ä¸€æ­¥

æ­å–œä½ å®Œæˆäº†å¿«é€Ÿå…¥é—¨ï¼æ¥ä¸‹æ¥å­¦ä¹ ï¼š

- ğŸ“˜ [æ™ºèƒ½ä½“é…ç½®è¯¦è§£](./02-agent-configuration.md) - æ·±å…¥ç†è§£å„ç§é…ç½®å‚æ•°
- ğŸ“— [å¤šæ™ºèƒ½ä½“åä½œå®æˆ˜](./03-multi-agent-workflow.md) - æ„å»ºå¤æ‚çš„å·¥ä½œæµ

---

**æœ‰ç–‘é—®ï¼Ÿ** æŸ¥çœ‹ [AutoGen å®˜æ–¹æ–‡æ¡£](https://microsoft.github.io/autogen/) æˆ–å‚è€ƒé¡¹ç›®æºç  `backend/app/llm/autogen_runner.py`
