# LLM provider configuration
LLM_PROVIDER=qwen
QWEN_API_KEY=REPLACE_WITH_YOUR_QWEN_API_KEY
QWEN_BASE_URL=https://dashscope.aliyuncs.com/compatible-mode/v1
QWEN_MODEL=qwen-plus
LLM_MODE=autogen
LLM_TIMEOUT=120

# Vision-Language (VL) for image analysis
# 使用同一个 QWEN_API_KEY，无需单独 VL 密钥
VL_ENABLED=true

# VL引擎选择: "paddleocr" (本地推理, 无需API key) 或 "qwen" (在线API)
# PaddleOCR优势: 本地推理、数据安全、无API成本、支持109种语言、专为文档解析优化
# Qwen VL优势: 云端API、无需GPU、快速部署
VL_ENGINE=paddleocr  # 可选: paddleocr | qwen

# Qwen VL配置 (仅当 VL_ENGINE=qwen 时需要)
VL_MODEL=qwen-vl-plus
# VL_BASE_URL=  # 可选，默认使用 QWEN_BASE_URL

# 智能体专用模型配置（仅配置模型名；密钥统一用 QWEN_API_KEY）
# 需求分析师 - 使用最强模型
ANALYSIS_AGENT_MODEL=qwen-max
#+ ANALYSIS_AGENT_BASE_URL=  # 可选，默认使用 QWEN_BASE_URL

# 测试工程师 - 使用平衡模型
TEST_AGENT_MODEL=qwen-plus
#+ TEST_AGENT_BASE_URL=  # 可选，默认使用 QWEN_BASE_URL

# 质量评审专家 - 使用平衡模型
REVIEW_AGENT_MODEL=qwen-plus
#+ REVIEW_AGENT_BASE_URL=  # 可选，默认使用 QWEN_BASE_URL

# Application options
APP_HOST=0.0.0.0
APP_PORT=8000
DEBUG=true

# Persistence
DATABASE_URL=sqlite+aiosqlite:///./ai_requirement.db
# 若要使用内存模拟，可改为 fakeredis://
REDIS_URL=redis://redis:6379/0
SESSION_TTL_HOURS=72
SESSION_CLEANUP_INTERVAL=3600

# Uploads
MAX_FILE_SIZE=10485760
# 与 docker-compose 保持一致，写入容器内的 /tmp/uploads（已挂载为持久卷）
UPLOAD_DIR=/tmp/uploads
